{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achalbajpai/building-llms/blob/main/Vector_embedding_using_Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VBZDi1dwyJtM"
      },
      "outputs": [],
      "source": [
        "#pip install gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkv2bnc2Mh1y"
      },
      "source": [
        "# Import trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCPkvuHFy16u",
        "outputId": "d20d1c52-682e-452d-c9ec-eff3c57b8ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "model = api.load(\"word2vec-google-news-300\")  # download the model and return as object ready for use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox1KWfS1Msne"
      },
      "source": [
        "# Example of a word as a vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_AMdizk0wVA",
        "outputId": "4f14e4cd-2f39-4dba-82b6-47cd1cc31988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.15820312 -0.0090332   0.20507812  0.2578125   0.06298828 -0.07373047\n",
            "  0.08984375 -0.16210938  0.33789062  0.1875     -0.01306152 -0.20605469\n",
            " -0.28320312  0.10351562  0.13574219  0.44140625  0.15039062  0.10400391\n",
            "  0.16796875 -0.0222168  -0.07226562 -0.25585938  0.38476562 -0.12988281\n",
            " -0.0456543  -0.11962891 -0.14453125 -0.19726562 -0.05908203 -0.13476562\n",
            " -0.10400391  0.17285156  0.02246094 -0.09912109 -0.3984375   0.265625\n",
            " -0.19335938  0.28710938  0.2421875   0.203125    0.00637817 -0.14648438\n",
            "  0.36523438  0.05712891  0.20117188 -0.11083984  0.578125   -0.3671875\n",
            " -0.34765625  0.2578125  -0.12353516  0.0112915   0.01000977 -0.07470703\n",
            " -0.06494141  0.07568359 -0.11181641  0.05761719 -0.02844238 -0.15722656\n",
            " -0.03271484  0.48046875 -0.20898438 -0.29882812  0.22363281 -0.11376953\n",
            " -0.04638672 -0.3515625  -0.0027771   0.03930664  0.02697754  0.37695312\n",
            " -0.16210938  0.25585938 -0.08349609 -0.03149414 -0.05322266 -0.19726562\n",
            " -0.12158203 -0.1953125  -0.30273438  0.171875   -0.34179688 -0.09082031\n",
            "  0.359375    0.15332031  0.3046875   0.42773438  0.00337219  0.02612305\n",
            "  0.13867188 -0.01733398 -0.50390625  0.09814453 -0.14746094 -0.28515625\n",
            " -0.22851562 -0.10302734  0.68359375 -0.04174805 -0.203125   -0.01721191\n",
            "  0.22558594  0.17675781  0.04150391  0.328125    0.2109375  -0.25195312\n",
            "  0.16308594 -0.07714844 -0.05395508 -0.08496094  0.04443359  0.28125\n",
            " -0.0612793   0.23828125 -0.40820312 -0.21972656  0.14160156 -0.14453125\n",
            "  0.125      -0.26171875 -0.06396484  0.08203125  0.18261719 -0.41210938\n",
            " -0.40429688  0.26757812 -0.16113281 -0.12988281 -0.3671875   0.00454712\n",
            "  0.22753906 -0.09130859  0.24902344 -0.328125   -0.25390625 -0.11621094\n",
            "  0.16796875  0.13183594  0.38867188 -0.28320312  0.15625    -0.18164062\n",
            " -0.14941406  0.02270508 -0.17675781 -0.02526855  0.02209473 -0.453125\n",
            "  0.27734375 -0.15527344 -0.41796875 -0.14746094 -0.28320312 -0.17871094\n",
            "  0.10839844  0.2890625   0.1171875  -0.16503906  0.12597656  0.06005859\n",
            "  0.00634766 -0.04101562  0.07714844 -0.41015625  0.38671875  0.00354004\n",
            " -0.51171875  0.30273438 -0.54296875  0.12890625 -0.20214844  0.0859375\n",
            " -0.20117188 -0.00376892  0.515625   -0.45117188  0.0859375  -0.51171875\n",
            "  0.18359375  0.30273438  0.07373047  0.20117188  0.06835938  0.15625\n",
            " -0.06835938  0.06396484  0.25976562  0.01348877 -0.08007812  0.0480957\n",
            " -0.09814453 -0.10253906  0.59375     0.01574707 -0.44335938  0.23046875\n",
            " -0.43164062 -0.51953125 -0.36523438 -0.36914062 -0.23925781 -0.45117188\n",
            " -0.15625    -0.4921875   0.22753906 -0.14550781 -0.31445312 -0.06884766\n",
            "  0.15917969 -0.00332642 -0.40820312 -0.15917969 -0.33007812  0.19238281\n",
            "  0.15722656 -0.03759766 -0.3046875   0.09765625 -0.22460938  0.08105469\n",
            "  0.23535156  0.16015625  0.29882812 -0.04541016  0.17578125  0.0625\n",
            "  0.16796875 -0.25195312 -0.00933838  0.09082031  0.10058594  0.08056641\n",
            "  0.12207031  0.14453125  0.01464844 -0.17773438 -0.03173828  0.20800781\n",
            "  0.3203125   0.15429688  0.15722656 -0.03125    -0.390625    0.21777344\n",
            " -0.2890625   0.05322266 -0.22167969  0.0612793   0.33984375  0.16015625\n",
            "  0.3203125   0.27734375  0.39257812 -0.08007812  0.06591797 -0.05566406\n",
            " -0.13769531  0.24023438  0.20117188 -0.13183594  0.02856445 -0.05078125\n",
            "  0.13378906 -0.20996094 -0.421875   -0.06445312  0.0456543  -0.15527344\n",
            " -0.31835938 -0.03808594 -0.17773438  0.0300293  -0.03442383  0.20117188\n",
            "  0.07910156  0.01116943 -0.48046875  0.296875   -0.20214844  0.0057373\n",
            "  0.2421875  -0.10400391 -0.34765625  0.02307129  0.3671875   0.16796875\n",
            "  0.02258301  0.00695801  0.07666016  0.4765625  -0.17285156  0.4453125\n",
            " -0.31640625  0.1328125  -0.27148438  0.16796875 -0.11572266  0.22363281]\n"
          ]
        }
      ],
      "source": [
        "word_vectors=model\n",
        "\n",
        "# Let us look how the vector embedding of a word looks like\n",
        "print(word_vectors['ronaldo'])  # Example: Accessing the vector for the word 'computer'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_vectors['cat'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP4wMXZQsXyf",
        "outputId": "caa8abbd-ac5c-4985-819e-f050ad91a199"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6BqaeOZM0WB"
      },
      "source": [
        "# Similar words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUPKTu3MOg8j"
      },
      "source": [
        "# King + Woman - Man = ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtXyb8ERMyZd",
        "outputId": "cce52534-592f-4b37-ac35-efb0e7dd35d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('queen', 0.7118193507194519), ('monarch', 0.6189674139022827), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321839332581), ('kings', 0.5236844420433044), ('Queen_Consort', 0.5235945582389832), ('queens', 0.5181134343147278), ('sultan', 0.5098593831062317), ('monarchy', 0.5087411999702454)]\n"
          ]
        }
      ],
      "source": [
        "# Example of using most_similar\n",
        "print(word_vectors.most_similar(positive=['king', 'woman'], negative=['man'], topn=10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzQ2Ibo3M5DY"
      },
      "source": [
        "# Let us check the similarity b/w a few pair of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eMx9DkoM802",
        "outputId": "c763f9f3-b39c-40b3-9c07-1e81fcbe2fdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.76640123\n",
            "0.6510957\n",
            "0.53705174\n",
            "0.78799146\n",
            "0.12199123\n",
            "0.11408084\n"
          ]
        }
      ],
      "source": [
        "# Example of calculating similarity\n",
        "print(word_vectors.similarity('woman', 'man'))\n",
        "print(word_vectors.similarity('king', 'queen'))\n",
        "print(word_vectors.similarity('chai', 'coffee'))\n",
        "print(word_vectors.similarity('ronaldo', 'messi'))\n",
        "print(word_vectors.similarity('python', 'javascript'))\n",
        "print(word_vectors.similarity('paper', 'water'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clOg4fnsOIqE"
      },
      "source": [
        "# Most similar words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "raqRgaROOKlb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2da11e7-63af-496b-d48b-b558f04e5452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('towers', 0.8531750440597534), ('skyscraper', 0.6417425870895386), ('Tower', 0.639177143573761), ('spire', 0.594687819480896), ('responded_Understood_Atlasjet', 0.5931612253189087)]\n"
          ]
        }
      ],
      "source": [
        "print(word_vectors.most_similar(\"tower\", topn=5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3BXCeFkMxuU"
      },
      "source": [
        "# Now let us see the vector similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo0Q3I5H2naW",
        "outputId": "e9d1e3f2-07f3-4660-b48a-c07f02ac4f09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The magnitude of the difference between 'man' and 'woman' is 1.73\n",
            "The magnitude of the difference between 'semiconductor' and 'earthworm' is 5.67\n",
            "The magnitude of the difference between 'nephew' and 'niece' is 1.96\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# Words to compare\n",
        "word1 = 'man'\n",
        "word2 = 'woman'\n",
        "\n",
        "word3 = 'semiconductor'\n",
        "word4 = 'earthworm'\n",
        "\n",
        "word5 = 'nephew'\n",
        "word6 = 'niece'\n",
        "\n",
        "# Calculate the vector difference\n",
        "vector_difference1 = model[word1] - model[word2]\n",
        "vector_difference2 = model[word3] - model[word4]\n",
        "vector_difference3 = model[word5] - model[word6]\n",
        "\n",
        "# Calculate the magnitude of the vector difference\n",
        "magnitude_of_difference1 = np.linalg.norm(vector_difference1)\n",
        "magnitude_of_difference2 = np.linalg.norm(vector_difference2)\n",
        "magnitude_of_difference3 = np.linalg.norm(vector_difference3)\n",
        "\n",
        "\n",
        "# Print the magnitude of the difference\n",
        "print(\"The magnitude of the difference between '{}' and '{}' is {:.2f}\".format(word1, word2, magnitude_of_difference1))\n",
        "print(\"The magnitude of the difference between '{}' and '{}' is {:.2f}\".format(word3, word4, magnitude_of_difference2))\n",
        "print(\"The magnitude of the difference between '{}' and '{}' is {:.2f}\".format(word5, word6, magnitude_of_difference3))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}